{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# to transform words in vectors and to build and organize models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# to process words\n",
    "# to download nltk packages de-comment next line\n",
    "# nltk.download() \n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.snowball import ItalianStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'brand_id', 'worker_id', 'mturker',\n",
       "       'post_hash', 'answer', 'date', 'duration_seconds', 'text',\n",
       "       'model_decision', 'timestamped_model', 'lang'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "src = pd.read_csv('../../Data/tribe_dynamics_data.csv')\n",
    "src.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['labels', 'lang', 'link', 'model_decision', 'mturker', 'text'], dtype='object')"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "src2 = pd.read_json('../../Data/CSE_20180215/14680_data.json')\n",
    "src2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labels_list_unpacking(list_of_label_lists):\n",
    "    # Count number of True and False and convert with majority\n",
    "    new_labels_list = []\n",
    "\n",
    "    for label_list in list_of_label_lists:\n",
    "        labels_counter = Counter(label_list)\n",
    "        if labels_counter[0] >= labels_counter[1]:  # Prefer false negatives to false positives\n",
    "            new_labels_list.append(False)\n",
    "        else:\n",
    "            new_labels_list.append(True)\n",
    "\n",
    "    return np.array(new_labels_list)\n",
    "\n",
    "\n",
    "def replace_label_column_in_df(df):\n",
    "    # Converts list of labels into True or False\n",
    "    # new_labels_arr = labels_list_unpacking(df.labels.values) # ERROR: 'DataFrame' object has no attribute 'labels' (Why???)\n",
    "    new_labels_arr = labels_list_unpacking(df.iloc[:, 0].values)\n",
    "\n",
    "    df['answer'] = new_labels_arr\n",
    "\n",
    "    # Return df without 'labels' column, replaced by 'answer' one\n",
    "    return df[['lang', 'link', 'model_decision', 'mturker', 'text', 'answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lang', 'link', 'model_decision', 'mturker', 'text', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src2 = replace_label_column_in_df(src2)\n",
    "src2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src=src2[['answer','text','lang']]\n",
    "multi_languages = src[(src.lang == 'en') | (src.lang == 'it')]\n",
    "mono_language_ita = src[src['lang'] == 'it']\n",
    "mono_language_eng = src[src['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def imbalance_ratio(labels_arr):\n",
    "    counter_obj = Counter(labels_arr)\n",
    "    num_true = counter_obj[True]\n",
    "    num_false = counter_obj[False]\n",
    "    if (num_true == 0) and (num_false == 0):  # Avoid division by zero\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (min(num_true, num_false) / max(num_true, num_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts in all languages have an imbalance ratio is 0.10113302559798576\n",
      "texts in english have an imbalance ratio is 0.4490582191780822\n",
      "texts in italian have an imbalance ratio is 0.9450292397660819\n"
     ]
    }
   ],
   "source": [
    "print('texts in all languages have an imbalance ratio is',imbalance_ratio(multi_languages['answer']))\n",
    "print('texts in english have an imbalance ratio is',imbalance_ratio(mono_language_eng['answer']))\n",
    "print('texts in italian have an imbalance ratio is',imbalance_ratio(mono_language_ita['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\popor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# convert False to 0s and True to 1s\n",
    "src['answer'] = (src['answer'] == True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4525, 3) (902, 3) (3623, 3)\n"
     ]
    }
   ],
   "source": [
    "# select posts language (i.e. english and italian)\n",
    "src=src[['answer','text','lang']]\n",
    "df_all = src[(src.lang == 'en') | (src.lang == 'it')]\n",
    "df_ita = src[src['lang'] == 'it']\n",
    "df_eng = src[src['lang'] == 'en']\n",
    "print(df_all.shape, df_ita.shape, df_eng.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 3)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomely extract a data sample of same name observation as other dataframe\n",
    "df_eng_reduced = df_eng.sample(n=df_ita.shape[0])\n",
    "df_eng_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 3)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#divide df in english among true and false\n",
    "df_eng_true = df_eng[df_eng['answer'] == True]\n",
    "df_eng_false = df_eng[df_eng['answer'] == False]\n",
    "#randomely select true and false as in the dataframe of posts in italian\n",
    "df_eng_reduced_true = df_eng_true.sample(n=df_ita[df_ita['answer'] == True].shape[0])\n",
    "df_eng_reduced_false = df_eng_false.sample(n=df_ita[df_ita['answer'] == False].shape[0])\n",
    "#combine true and false of the reduced dataframe\n",
    "df_eng_reduced_weighted = pd.concat([df_eng_reduced_true, df_eng_reduced_false])\n",
    "df_eng_reduced_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert text and classifier in arrays\n",
    "X_all = np.asarray(df_all['text'])\n",
    "Y_all = np.asarray(df_all['answer'], dtype=\"|S6\")\n",
    "X_eng = np.asarray(df_eng['text'])\n",
    "Y_eng = np.asarray(df_eng['answer'], dtype=\"|S6\")\n",
    "X_eng_reduced = np.asarray(df_eng_reduced['text'])\n",
    "Y_eng_reduced = np.asarray(df_eng_reduced['answer'], dtype=\"|S6\")\n",
    "X_eng_reduced_weighted = np.asarray(df_eng_reduced_weighted['text'])\n",
    "Y_eng_reduced_weighted = np.asarray(df_eng_reduced_weighted['answer'], dtype=\"|S6\")\n",
    "X_ita = np.asarray(df_ita['text'])\n",
    "Y_ita = np.asarray(df_ita['answer'], dtype=\"|S6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split in train and test\n",
    "X_train_all, X_test_all, Y_train_all, Y_test_all = train_test_split(X_all, Y_all, test_size=0.4, random_state=42)\n",
    "X_train_eng, X_test_eng, Y_train_eng, Y_test_eng = train_test_split(X_eng, Y_eng, test_size=0.4, random_state=42)\n",
    "X_train_eng_reduced, X_test_eng_reduced, Y_train_eng_reduced, Y_test_eng_reduced = train_test_split(X_eng_reduced, Y_eng_reduced, test_size=0.4, random_state=42)\n",
    "X_train_eng_reduced_weighted, X_test_eng_reduced_weighted, Y_train_eng_reduced_weighted, Y_test_eng_reduced_weighted = train_test_split(X_eng_reduced_weighted, Y_eng_reduced_weighted, test_size=0.4, random_state=42)\n",
    "X_train_ita, X_test_ita, Y_train_ita, Y_test_ita = train_test_split(X_ita, Y_ita, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'0' b'1287']\n",
      " [b'1' b'2336']]\n"
     ]
    }
   ],
   "source": [
    "# Posts written in English\n",
    "# number of datapoints labeled False and True\n",
    "unique, counts = np.unique(Y_eng, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'0' b'788']\n",
      " [b'1' b'1385']]\n"
     ]
    }
   ],
   "source": [
    "# Posts written in English : train set\n",
    "unique, counts = np.unique(Y_train_eng, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'0' b'290']\n",
      " [b'1' b'612']]\n"
     ]
    }
   ],
   "source": [
    "# Posts written in English from reduced dataframe: train set\n",
    "unique, counts = np.unique(Y_eng_reduced, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'0' b'512']\n",
      " [b'1' b'29']]\n"
     ]
    }
   ],
   "source": [
    "# Posts written in English from reduced dataframe with same amount True and False as the other dataframe: train set\n",
    "unique, counts = np.unique(Y_train_eng_reduced_weighted, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'0' b'511']\n",
      " [b'1' b'30']]\n"
     ]
    }
   ],
   "source": [
    "# Posts written in Italian: train set\n",
    "# number of datapoints labeled False and True\n",
    "unique, counts = np.unique(Y_train_ita, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of words for english posts\n",
    "# this class create steems words and ignore stopwords\n",
    "# using CountVectorizer methods each unique word in the dictionary will correspond to a feature\n",
    "stemmer_eng = SnowballStemmer(\"english\", ignore_stopwords=False)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer_eng.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect_eng = StemmedCountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run ML algorithm\n",
    "# build pipeline for Naive Bayes classifier\n",
    "# control for Term Frequencies (i.e. #count(word) / #Total words)\n",
    "# control for Term Frequency times inverse document frequency (i.e. weightage of more common words like the, is, an etc.) \n",
    "text_stemmed_eng = Pipeline([('vect', stemmed_count_vect_eng),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('mnb', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84896551724137936"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of NB Classifier for posts in english\n",
    "text_stemmed_eng = text_stemmed_eng.fit(X_train_eng, Y_train_eng)\n",
    "predicted_stemmed_eng = text_stemmed_eng.predict(X_test_eng)\n",
    "np.mean(predicted_stemmed_eng == Y_test_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9369737 ,  0.90159827,  0.61559327,  0.64240181,  0.47063031,\n",
       "        0.89216549,  0.98486342,  0.53921185,  0.24284458,  0.17446629])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob_stemmed_eng = text_stemmed_eng.predict_proba(X_test_eng)[:, 1]\n",
    "#print first ten probabilities\n",
    "y_pred_prob_stemmed_eng[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848965517241\n",
      "0.945903373519\n",
      "0.97054187543\n"
     ]
    }
   ],
   "source": [
    "#Y_test_eng\n",
    "Y_test_eng2 = np.array(Y_test_eng, dtype='int')\n",
    "\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import average_precision_score\n",
    "\n",
    "#print(metrics.precision_score(y_test, y_pred_class))\n",
    "\n",
    "#accuracy\n",
    "print(metrics.accuracy_score(Y_test_eng, predicted_stemmed_eng))\n",
    "#ROC score\n",
    "print(metrics.roc_auc_score(Y_test_eng2, y_pred_prob_stemmed_eng))\n",
    "#average precision\n",
    "print(metrics.average_precision_score(Y_test_eng2, y_pred_prob_stemmed_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beauti', 'bodi', 'care', 'dove', 'hair', 'product']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract words from the vectorizer and probabilities for each word from the NB model trained\n",
    "list_words=text_stemmed_eng.named_steps['vect'].get_feature_names()\n",
    "list_prob=text_stemmed_eng.named_steps['mnb'].feature_log_prob_[1]\n",
    "#zip words and probabilities into a tuple\n",
    "words_prob=list(zip(list_words, list_prob))\n",
    "#take words with highest probability for the dove classifier of english posts\n",
    "words_high_probability = [t[0] for t in words_prob if t[1] > - 6.40]\n",
    "words_high_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 1st [-6.1802252269748479]\n",
      "prob 2 [-6.2884714819375054]\n",
      "prob 3 [-6.0461948848231852]\n",
      "prob 4 [-5.3005016698314584]\n",
      "prob 5 [-6.3497405390604413]\n",
      "prob 6th [-6.304891317261955]\n"
     ]
    }
   ],
   "source": [
    "#print frequent words' probabilities\n",
    "print('prob 1st',[t[1] for t in words_prob if t[0] == words_high_probability[0]])\n",
    "print('prob 2',[t[1] for t in words_prob if t[0] == words_high_probability[1]])\n",
    "print('prob 3',[t[1] for t in words_prob if t[0] == words_high_probability[2]])\n",
    "print('prob 4',[t[1] for t in words_prob if t[0] == words_high_probability[3]])\n",
    "print('prob 5',[t[1] for t in words_prob if t[0] == words_high_probability[4]])\n",
    "print('prob 6th',[t[1] for t in words_prob if t[0] == words_high_probability[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for english posts\n",
    "# List of parameters for which we would like to do performance tuning. \n",
    "# vect__ngram_range is telling to use unigram and bigrams and choose the optimal\n",
    "parameters_eng = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "#pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "# parameters and n_jobs=-1 which tells to use multiple cores from user machine\n",
    "gs_clf_eng = GridSearchCV(text_stemmed_eng, parameters_eng, n_jobs = 2,verbose=10) #, n_jobs=-1\n",
    "gs_clf_eng = gs_clf_eng.fit(X_train_eng, Y_train_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# italian posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of words for italian posts\n",
    "stemmer_ita = ItalianStemmer(ignore_stopwords=False)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer_ita.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect_ita = StemmedCountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build pipeline for Naive Bayes classifier\n",
    "text_stemmed_ita = Pipeline([('vect', stemmed_count_vect_ita),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('mnb', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96121883656509699"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of NB Classifier for posts in italian\n",
    "text_stemmed_ita = text_stemmed_ita.fit(X_train_ita, Y_train_ita)\n",
    "predicted_stemmed_ita = text_stemmed_ita.predict(X_test_ita)\n",
    "np.mean(predicted_stemmed_ita == Y_test_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1101371 ,  0.13361574,  0.22257561,  0.18704327,  0.05405698,\n",
       "        0.07035018,  0.18847392,  0.02618945,  0.07749913,  0.11917031])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob_stemmed_ita = text_stemmed_ita.predict_proba(X_test_ita)[:, 1]\n",
    "#print first ten probabilities\n",
    "y_pred_prob_stemmed_ita[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961218836565\n",
      "0.763508891929\n",
      "0.352013560566\n"
     ]
    }
   ],
   "source": [
    "#Y_test_eng\n",
    "Y_test_ita2 = np.array(Y_test_ita, dtype='int')\n",
    "#accuracy\n",
    "print(metrics.accuracy_score(Y_test_ita, predicted_stemmed_ita))\n",
    "#ROC score\n",
    "print(metrics.roc_auc_score(Y_test_ita2, y_pred_prob_stemmed_ita))\n",
    "#average precision\n",
    "print(metrics.average_precision_score(Y_test_ita2, y_pred_prob_stemmed_ita))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bagnoschium', 'donn', 'dov', 'il', 'per', 'scopr']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract words from the vectorizer and probabilities for each word from the NB model trained\n",
    "list_words_ita=text_stemmed_ita.named_steps['vect'].get_feature_names()\n",
    "list_prob_ita=text_stemmed_ita.named_steps['mnb'].feature_log_prob_[1]\n",
    "#zip words and probabilities into a tuple\n",
    "words_prob_ita=list(zip(list_words_ita, list_prob_ita))\n",
    "#take words with highest probability for the dove classifier of english posts\n",
    "words_high_probability_ita = [t[0] for t in words_prob_ita if t[1] > - 7.819]\n",
    "words_high_probability_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 1st [-7.8184415258763496]\n",
      "prob 2 [-7.7176600530044608]\n",
      "prob 3 [-7.5270358451820183]\n",
      "prob 4 [-7.6986028982367083]\n",
      "prob 5 [-7.7917494575301278]\n",
      "prob 6th [-7.7136145057812691]\n"
     ]
    }
   ],
   "source": [
    "#print frequent words' probabilities\n",
    "print('prob 1st',[t[1] for t in words_prob_ita if t[0] == words_high_probability_ita[0]])\n",
    "print('prob 2',[t[1] for t in words_prob_ita if t[0] == words_high_probability_ita[1]])\n",
    "print('prob 3',[t[1] for t in words_prob_ita if t[0] == words_high_probability_ita[2]])\n",
    "print('prob 4',[t[1] for t in words_prob_ita if t[0] == words_high_probability_ita[3]])\n",
    "print('prob 5',[t[1] for t in words_prob_ita if t[0] == words_high_probability_ita[4]])\n",
    "print('prob 6th',[t[1] for t in words_prob_ita if t[0] == words_high_probability_ita[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#English reduced and weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of words for english posts\n",
    "# this class create steems words and ignore stopwords\n",
    "# using CountVectorizer methods each unique word in the dictionary will correspond to a feature\n",
    "stemmer_eng = SnowballStemmer(\"english\", ignore_stopwords=False)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer_eng.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect_eng = StemmedCountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run ML algorithm\n",
    "# build pipeline for Naive Bayes classifier\n",
    "# control for Term Frequencies (i.e. #count(word) / #Total words)\n",
    "# control for Term Frequency times inverse document frequency (i.e. weightage of more common words like the, is, an etc.) \n",
    "text_stemmed_eng = Pipeline([('vect', stemmed_count_vect_eng),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('mnb', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94459833795013848"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of NB Classifier for posts in english dataframe reduced\n",
    "text_stemmed_eng_reduced_weighted = text_stemmed_eng.fit(X_train_eng_reduced_weighted, Y_train_eng_reduced_weighted)\n",
    "predicted_stemmed_eng_reduced_weighted = text_stemmed_eng.predict(X_test_eng_reduced_weighted)\n",
    "np.mean(predicted_stemmed_eng_reduced_weighted == Y_test_eng_reduced_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3884763 ,  0.36269865,  0.1193639 ,  0.50981856,  0.37682377,\n",
       "        0.41098333,  0.36544023,  0.43208678,  0.45923406,  0.43031114])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob_stemmed_eng_red_weight = text_stemmed_eng_reduced_weighted.predict_proba(X_test_ita)[:, 1]\n",
    "#print first ten probabilities\n",
    "y_pred_prob_stemmed_eng_red_weight[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94459833795\n",
      "0.435941043084\n",
      "0.0429233381304\n"
     ]
    }
   ],
   "source": [
    "#Y_test_eng\n",
    "Y_test_eng2_red_weight = np.array(Y_test_eng_reduced_weighted, dtype='int')\n",
    "\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import average_precision_score\n",
    "\n",
    "#print(metrics.precision_score(y_test, y_pred_class))\n",
    "\n",
    "#accuracy\n",
    "print(metrics.accuracy_score(Y_test_eng_reduced_weighted, predicted_stemmed_eng_reduced_weighted))\n",
    "#ROC score\n",
    "print(metrics.roc_auc_score(Y_test_eng2_red_weight, y_pred_prob_stemmed_eng_red_weight))\n",
    "#average precision\n",
    "print(metrics.average_precision_score(Y_test_eng2_red_weight, y_pred_prob_stemmed_eng_red_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bodi', 'care', 'dove', 'dri', 'hair', 'product']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract words from the vectorizer and probabilities for each word from the NB model trained\n",
    "list_words_eng_red_weight=text_stemmed_eng_reduced_weighted.named_steps['vect'].get_feature_names()\n",
    "list_prob_eng_red_weight=text_stemmed_eng_reduced_weighted.named_steps['mnb'].feature_log_prob_[1]\n",
    "#zip words and probabilities into a tuple\n",
    "words_prob_eng_red_weight=list(zip(list_words_eng_red_weight, list_prob_eng_red_weight))\n",
    "#take words with highest probability for the dove classifier of english posts\n",
    "words_high_probability_eng_red_weight = [t[0] for t in words_prob_eng_red_weight if t[1] > - 7.78]\n",
    "words_high_probability_eng_red_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 1st [-7.7262878214566131]\n",
      "prob 2 [-7.5834467806380816]\n",
      "prob 3 [-7.5276208095301822]\n",
      "prob 4 [-7.7740204544286629]\n",
      "prob 5 [-7.4419484410837473]\n",
      "prob 6th [-7.7401631537230111]\n"
     ]
    }
   ],
   "source": [
    "#print frequent words' probabilities\n",
    "print('prob 1st',[t[1] for t in words_prob_eng_red_weight if t[0] == words_high_probability_eng_red_weight[0]])\n",
    "print('prob 2',[t[1] for t in words_prob_eng_red_weight if t[0] == words_high_probability_eng_red_weight[1]])\n",
    "print('prob 3',[t[1] for t in words_prob_eng_red_weight if t[0] == words_high_probability_eng_red_weight[2]])\n",
    "print('prob 4',[t[1] for t in words_prob_eng_red_weight if t[0] == words_high_probability_eng_red_weight[3]])\n",
    "print('prob 5',[t[1] for t in words_prob_eng_red_weight if t[0] == words_high_probability_eng_red_weight[4]])\n",
    "print('prob 6th',[t[1] for t in words_prob_eng_red_weight if t[0] == words_high_probability_eng_red_weight[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_ita_stemmed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-1bbb2d149e76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                'clf__alpha': (1e-2, 1e-3)}\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgs_clf_ita\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_ita_stemmed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_ita\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mgs_clf_ita\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_clf_ita\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_ita\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_ita\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_ita_stemmed' is not defined"
     ]
    }
   ],
   "source": [
    "# Grid Search for italian posts\n",
    "parameters_ita = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],  #from unigrams to fourgrams\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "gs_clf_ita = GridSearchCV(text_ita_stemmed, parameters_ita, n_jobs=-1)\n",
    "gs_clf_ita = gs_clf_ita.fit(X_train_ita, Y_train_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of NB Classifier for posts in english dataframe reduced\n",
    "text_stemmed_eng_reduced = text_stemmed_eng.fit(X_train_eng_reduced, Y_train_eng_reduced)\n",
    "predicted_stemmed_eng_reduced = text_stemmed_eng.predict(X_test_eng_reduced)\n",
    "np.mean(predicted_stemmed_eng_reduced == Y_test_eng_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# measure performance for english posts\n",
    "print(gs_clf_eng.best_score_)\n",
    "print(gs_clf_eng.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# measure performance for italian posts\n",
    "print(gs_clf_ita.best_score_)\n",
    "print(gs_clf_ita.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Future improvements: TODO\n",
    "\n",
    "# implement a more general class StemmedCountVectorizer allowing for multiple languages \n",
    "# try with one bag of words and one classifier for both languages\n",
    "# try with a sample of the same size (50:50), and with different size (80:20)\n",
    "# try Gaussian, and Bernoulli Naive Bayes\n",
    "# Smooth parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
